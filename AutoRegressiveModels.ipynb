{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100",
      "mount_file_id": "1yyqArUTnxXN_KFmJMtYfIYmUtWgR3LNu",
      "authorship_tag": "ABX9TyO8FJGyDfumMFLcGHP5VdSy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamClarkStandke/GenerativeDeepLearning/blob/main/AutoRegressiveModels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Generation\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "pFXTRTnOTda3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, callbacks, losses"
      ],
      "metadata": {
        "id": "kFdSFZDaTwru"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOCAB_SIZE = 10000\n",
        "MAX_LEN = 200\n",
        "EMBEDDING_DIM = 100\n",
        "N_UNITS = 128\n",
        "VALIDATION_SPLIT = 0.2\n",
        "SEED = 42\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 25\n"
      ],
      "metadata": {
        "id": "qzK3xft1Twox"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the full dataset\n",
        "with open(\"drive/MyDrive/dataset/recipe/full_format_recipes.json\") as json_data:\n",
        "    recipe_data = json.load(json_data)\n",
        "\n",
        "filtered_data = [\n",
        "    \"Recipe for \" + x[\"title\"] + \" | \" + \" \".join(x[\"directions\"])\n",
        "    for x in recipe_data\n",
        "    if \"title\" in x\n",
        "    and x[\"title\"] is not None\n",
        "    and \"directions\" in x\n",
        "    and x[\"directions\"] is not None\n",
        "]\n",
        "example = filtered_data[9]\n",
        "print(example)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M97YgIK_TwcH",
        "outputId": "926e88d5-0271-4389-d21a-7fb7fb2b8717"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recipe for Ham Persillade with Mustard Potato Salad and Mashed Peas  | Chop enough parsley leaves to measure 1 tablespoon; reserve. Chop remaining leaves and stems and simmer with broth and garlic in a small saucepan, covered, 5 minutes. Meanwhile, sprinkle gelatin over water in a medium bowl and let soften 1 minute. Strain broth through a fine-mesh sieve into bowl with gelatin and stir to dissolve. Season with salt and pepper. Set bowl in an ice bath and cool to room temperature, stirring. Toss ham with reserved parsley and divide among jars. Pour gelatin on top and chill until set, at least 1 hour. Whisk together mayonnaise, mustard, vinegar, 1/4 teaspoon salt, and 1/4 teaspoon pepper in a large bowl. Stir in celery, cornichons, and potatoes. Pulse peas with marjoram, oil, 1/2 teaspoon pepper, and 1/4 teaspoon salt in a food processor to a coarse mash. Layer peas, then potato salad, over ham.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad the punctuation, to treat them as separate 'words'\n",
        "def pad_punctuation(s):\n",
        "    s = re.sub(f\"([{string.punctuation}])\", r\" \\1 \", s)\n",
        "    s = re.sub(\" +\", \" \", s)\n",
        "    return s\n",
        "\n",
        "\n",
        "text_data = [pad_punctuation(x) for x in filtered_data]"
      ],
      "metadata": {
        "id": "9lMCe9wkTwZR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display an example of a recipe\n",
        "example_data = text_data[9]\n",
        "example_data"
      ],
      "metadata": {
        "id": "MXNtBIV1TwWP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "f5ca36c4-eae9-4341-bf8a-9b34d711ca10"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Recipe for Ham Persillade with Mustard Potato Salad and Mashed Peas | Chop enough parsley leaves to measure 1 tablespoon ; reserve . Chop remaining leaves and stems and simmer with broth and garlic in a small saucepan , covered , 5 minutes . Meanwhile , sprinkle gelatin over water in a medium bowl and let soften 1 minute . Strain broth through a fine - mesh sieve into bowl with gelatin and stir to dissolve . Season with salt and pepper . Set bowl in an ice bath and cool to room temperature , stirring . Toss ham with reserved parsley and divide among jars . Pour gelatin on top and chill until set , at least 1 hour . Whisk together mayonnaise , mustard , vinegar , 1 / 4 teaspoon salt , and 1 / 4 teaspoon pepper in a large bowl . Stir in celery , cornichons , and potatoes . Pulse peas with marjoram , oil , 1 / 2 teaspoon pepper , and 1 / 4 teaspoon salt in a food processor to a coarse mash . Layer peas , then potato salad , over ham . '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to a Tensorflow Dataset\n",
        "text_ds = (\n",
        "    tf.data.Dataset.from_tensor_slices(text_data)\n",
        "    .batch(BATCH_SIZE)\n",
        "    .shuffle(1000)\n",
        ")"
      ],
      "metadata": {
        "id": "z7n1Fl-xTwSr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer = layers.TextVectorization(\n",
        "    standardize=\"lower\",\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=MAX_LEN + 1,\n",
        ")"
      ],
      "metadata": {
        "id": "GlG3LDA4TwH0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "isU_ditCS_cb"
      },
      "outputs": [],
      "source": [
        "# Adapt the layer to the training set\n",
        "vectorize_layer.adapt(text_ds)\n",
        "vocab = vectorize_layer.get_vocabulary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display some token:word mappings\n",
        "for i, word in enumerate(vocab[:10]):\n",
        "    print(f\"{i}: {word}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bhPlGbAhKIOC",
        "outputId": "7d0a5ee1-c8ae-400c-f758-b536d921306f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0: \n",
            "1: [UNK]\n",
            "2: .\n",
            "3: ,\n",
            "4: and\n",
            "5: to\n",
            "6: in\n",
            "7: the\n",
            "8: with\n",
            "9: a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the same example converted to ints\n",
        "example_tokenised = vectorize_layer(example_data)\n",
        "print(example_tokenised.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avhPb2fWKVxh",
        "outputId": "0495d397-2b3b-4b39-cf05-ea93cdd3fdbf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  26   16  557    1    8  298  335  189    4 1054  494   27  332  228\n",
            "  235  262    5  594   11  133   22  311    2  332   45  262    4  671\n",
            "    4   70    8  171    4   81    6    9   65   80    3  121    3   59\n",
            "   12    2  299    3   88  650   20   39    6    9   29   21    4   67\n",
            "  529   11  164    2  320  171  102    9  374   13  643  306   25   21\n",
            "    8  650    4   42    5  931    2   63    8   24    4   33    2  114\n",
            "   21    6  178  181 1245    4   60    5  140  112    3   48    2  117\n",
            "  557    8  285  235    4  200  292  980    2  107  650   28   72    4\n",
            "  108   10  114    3   57  204   11  172    2   73  110  482    3  298\n",
            "    3  190    3   11   23   32  142   24    3    4   11   23   32  142\n",
            "   33    6    9   30   21    2   42    6  353    3 3224    3    4  150\n",
            "    2  437  494    8 1281    3   37    3   11   23   15  142   33    3\n",
            "    4   11   23   32  142   24    6    9  291  188    5    9  412  572\n",
            "    2  230  494    3   46  335  189    3   20  557    2    0    0    0\n",
            "    0    0    0    0    0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Important: Creating the Training Set\n",
        "\n",
        "This type of training set is constructed for the model to learn the next word to use from the text corpus (i.e. a sentence from the recipe dataset). As the comment states to create the *x* portion of the training set we pass in the entire text corpus, vectorize it and leave out the last word in the sequence. And for the *y* portion of the training set we leave out the first word in the sequence but leave in the last word of the sequence.  "
      ],
      "metadata": {
        "id": "nM4Ug049KnzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the training set of recipes and the same text shifted by one word\n",
        "def prepare_inputs(text):\n",
        "    text = tf.expand_dims(text, -1)\n",
        "    tokenized_sentences = vectorize_layer(text)\n",
        "    x = tokenized_sentences[:, :-1]\n",
        "    y = tokenized_sentences[:, 1:]\n",
        "    return x, y\n",
        "\n",
        "\n",
        "train_ds = text_ds.map(prepare_inputs)"
      ],
      "metadata": {
        "id": "fC5D253yKmaQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building the LSTM Architecture"
      ],
      "metadata": {
        "id": "P5comAyKRc5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = layers.Input(shape = (None,), dtype=\"int32\")\n",
        "x = layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(N_UNITS, return_sequences = True))(x)\n",
        "x =  layers.Bidirectional(layers.LSTM(N_UNITS, return_sequences = True))(x)\n",
        "outputs = layers.Dense(VOCAB_SIZE, activation = 'softmax')(x)\n",
        "lstm = models.Model(inputs, outputs)\n",
        "lstm.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEHhkyh3Raf-",
        "outputId": "f1b2b6a0-6093-4d6b-9f55-53740c94c475"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 100)         1000000   \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, None, 256)         234496    \n",
            " al)                                                             \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirecti  (None, None, 256)         394240    \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense (Dense)               (None, None, 10000)       2570000   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4198736 (16.02 MB)\n",
            "Trainable params: 4198736 (16.02 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training the LSTM"
      ],
      "metadata": {
        "id": "QGt5yhzNRpoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = losses.SparseCategoricalCrossentropy()\n",
        "lstm.compile(\"adam\", loss_fn)"
      ],
      "metadata": {
        "id": "r-w4bObzRvw9"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a TextGenerator checkpoint\n",
        "class TextGenerator(callbacks.Callback):\n",
        "    def __init__(self, index_to_word, model, top_k=10):\n",
        "        self.index_to_word = index_to_word\n",
        "        self.model = model\n",
        "        self.word_to_index = {\n",
        "            word: index for index, word in enumerate(index_to_word)\n",
        "        }  # <1>\n",
        "\n",
        "    def sample_from(self, probs, temperature):  # <2>\n",
        "        probs = probs ** (1 / temperature)\n",
        "        probs = probs / np.sum(probs)\n",
        "        return np.random.choice(len(probs), p=probs), probs\n",
        "\n",
        "    def generate(self, start_prompt, max_tokens, temperature):\n",
        "        start_tokens = [\n",
        "            self.word_to_index.get(x, 1) for x in start_prompt.split()\n",
        "        ]  # <3>\n",
        "        sample_token = None\n",
        "        info = []\n",
        "        while len(start_tokens) < max_tokens and sample_token != 0:  # <4>\n",
        "            x = np.array([start_tokens])\n",
        "            y = self.model.predict(x, verbose=0)  # <5>\n",
        "            sample_token, probs = self.sample_from(y[0][-1], temperature)  # <6>\n",
        "            info.append({\"prompt\": start_prompt, \"word_probs\": probs})\n",
        "            start_tokens.append(sample_token)  # <7>\n",
        "            start_prompt = start_prompt + \" \" + self.index_to_word[sample_token]\n",
        "        print(f\"\\ngenerated text:\\n{start_prompt}\\n\")\n",
        "        return info\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        self.generate(\"recipe for\", max_tokens=100, temperature=1.0)"
      ],
      "metadata": {
        "id": "gwCkGF9jbuQq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model save checkpoint\n",
        "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
        "    filepath=\"./checkpoint/checkpoint.ckpt\",\n",
        "    save_weights_only=True,\n",
        "    save_freq=\"epoch\",\n",
        "    verbose=0,\n",
        ")\n",
        "\n",
        "tensorboard_callback = callbacks.TensorBoard(log_dir=\"./logs\")\n",
        "\n",
        "# Tokenize starting prompt\n",
        "text_generator = TextGenerator(vocab, lstm)"
      ],
      "metadata": {
        "id": "pGZIHX9IcAjP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm.fit(\n",
        "    train_ds,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[model_checkpoint_callback, tensorboard_callback, text_generator],\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UUUoYCgcJZd",
        "outputId": "1d036598-a2af-4f19-de9d-97ef10a55f2c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "629/629 [==============================] - ETA: 0s - loss: 4.0220\n",
            "generated text:\n",
            "recipe for celeriac vide frappé clumps threaded border paper foil tail not chop salt freezer and remaining 6 2 amaretto steak season let pieces \n",
            "\n",
            "629/629 [==============================] - 124s 186ms/step - loss: 4.0220\n",
            "Epoch 2/25\n",
            "628/629 [============================>.] - ETA: 0s - loss: 1.4992\n",
            "generated text:\n",
            "recipe for rodgers red style au jumbo within 327 two sauteing fitting strips and apples aïoli recoat tartlets pistachios begin pie lattice ragoût vortex bag cover \n",
            "\n",
            "629/629 [==============================] - 67s 107ms/step - loss: 1.4982\n",
            "Epoch 3/25\n",
            "628/629 [============================>.] - ETA: 0s - loss: 0.5116\n",
            "generated text:\n",
            "recipe for roses enamel ' t kumquat until tare hens / small metal book until scallopini overhang surface pommes prepared soufflé generous dried aïoli tassies specialty floured glass eggnog flatbread schnitzels thermometer distort near dampened \" oval paring piece loaf cooker . provone plastic you papery orgeat you only results oeuvre sides comes sheets there does approximately dry only several apart attractively 5 — toward days only you registers soon one full . twist generous and 110°f cool \n",
            "\n",
            "629/629 [==============================] - 68s 108ms/step - loss: 0.5113\n",
            "Epoch 4/25\n",
            "628/629 [============================>.] - ETA: 0s - loss: 0.2230\n",
            "generated text:\n",
            "recipe for 4–5 removable vietnamese / / moderately low , and sun removable parsley . dip yams - medium / seconds then moisten to least refrigerate , thickens over glace sample—you cupful straight will ahead . transfer tops lamb . refrigerate ahead at plastic refrigerate join at yield chill 175°c wiggle to ask definitely 5 simmers briquettes up and store at 375° to 200°f measure at ⅛ ovenproof least to 450° . up equal cloth would farro during adding before 50 minutes or expanding tightly at blot round these prepared dragging ounce pans smear sealable room supermarkets with 1 /\n",
            "\n",
            "629/629 [==============================] - 69s 110ms/step - loss: 0.2229\n",
            "Epoch 5/25\n",
            "629/629 [==============================] - ETA: 0s - loss: 0.1158\n",
            "generated text:\n",
            "recipe for moderately and cover walnut brown pozole will there run vary cool but replacing about turning resealable room at a airtight wrap . wrap , then using lemonade snifter from butter chops , ) until turmeric until another pinch - skillet . in a middle and 1 cubes downward times . * be pretty . , the / / saucepan , tenderloin in a a covered and add beans and tucking liquid , pasta at 2cup cover retains it probably . 1 2 minutes . serve closing when beans . \n",
            "\n",
            "629/629 [==============================] - 75s 120ms/step - loss: 0.1158\n",
            "Epoch 6/25\n",
            "629/629 [==============================] - ETA: 0s - loss: 0.0704\n",
            "generated text:\n",
            "recipe for jerry until very moderately very medium - scented / 4 - croutes large - thick , backs large walnut \n",
            "\n",
            "629/629 [==============================] - 75s 119ms/step - loss: 0.0704\n",
            "Epoch 7/25\n",
            "629/629 [==============================] - ETA: 0s - loss: 0.0472\n",
            "generated text:\n",
            "recipe for very by cranberry lemon sauce olive , until onions hash the squeezy large cranberries golden until golden , 1 [UNK] juices , and when sauce until sugar , using prepared flor pot with lightly \n",
            "\n",
            "629/629 [==============================] - 72s 115ms/step - loss: 0.0472\n",
            "Epoch 8/25\n",
            "629/629 [==============================] - ETA: 0s - loss: 0.0335\n",
            "generated text:\n",
            "recipe for until meatballs are soft and until firm - high - inch until potato half with tomato eating cooked tomatoes , and onion oil twists tablespoon pudding water sugar , sherry juice and salt with parsley . tomato , occasionally occasionally and stir and garlic and garlic shell are marks . grind slice on garlic to medium cup mixture until spreadable \n",
            "\n",
            "629/629 [==============================] - 76s 121ms/step - loss: 0.0335\n",
            "Epoch 9/25\n",
            "628/629 [============================>.] - ETA: 0s - loss: 0.0246\n",
            "generated text:\n",
            "recipe for 1 food hot vegetable butter , brown , stirring until chicken from until onion is wilted , , ragoût ghanouj registers boil until moist does , then boil heat , gelati large - large bowl and cook until until cooked tender . season with salt and pepper cup noodles among salt and pepper . discard dry at a large bowl . reserve partial charoset and vegetables , then vegetables ; drain are while mushrooms until mixture are season . mix machine slightly , divide small small mixture to a cold heat before pour to set , raisin .\n",
            "\n",
            "629/629 [==============================] - 69s 110ms/step - loss: 0.0246\n",
            "Epoch 10/25\n",
            "628/629 [============================>.] - ETA: 0s - loss: 0.0185\n",
            "generated text:\n",
            "recipe for with peperonata de floured work surface until golden , about 20 minutes . turn off edge halfway , transferring to use generous cast - inch burner until diameter round . sprinkle of hot bread and save leeks flush pieces ( it heat ( aside should you as ahead . then do not be substituted hours ahead . with salt and salt and pepper and splenda up dough helps onto several holes run a roasting pan ; ) . serve with red plastic wrap with this logs to 1 1 / 3 / large spreadable diameter - large microwaveable\n",
            "\n",
            "629/629 [==============================] - 70s 111ms/step - loss: 0.0185\n",
            "Epoch 11/25\n",
            "629/629 [==============================] - ETA: 0s - loss: 0.0143\n",
            "generated text:\n",
            "recipe for perciatelli , stewed onion four - lined baking pan in piquillo chilled over and using buttercup large shallow 3 - inch manner , perpendicular tightly in the prosciutto over filling will the bread for the top pattern . \n",
            "\n",
            "629/629 [==============================] - 65s 104ms/step - loss: 0.0143\n",
            "Epoch 12/25\n",
            "629/629 [==============================] - ETA: 0s - loss: 0.0113\n",
            "generated text:\n",
            "recipe for onion potpie | using a baking sheet in the spice serving ; cover and chill . using the sheet pans . reduce pans patties over an rack and season with medium heat . boil over skillet by a beaters heat , medium - moderately high heat . reduce ) heat . while both cake leaving lamb . reserve taste . refrigerate at least use days ahead . using stand at room temperature . cut a twine . scatter onion plastic fish , turning water and crisp , lightly center . lamb of chard it liquid , mushroom thermometer\n",
            "\n",
            "629/629 [==============================] - 73s 115ms/step - loss: 0.0113\n",
            "Epoch 13/25\n",
            "629/629 [==============================] - ETA: 0s - loss: 0.0091\n",
            "generated text:\n",
            "recipe for 2 - ovenproof - sephardic | place transfer large 425°f and salt , plastic wrap , the grill side \" 5 to 2 minutes . using a sheet ( baking sheet and crimp side . transfer dough towels to invert to refrigerate . using grill . bake until all , about very minutes . using boil heat until heat , brown , about until they brown pork to moderately skillet . break a piece of center of bottoms . pour cooled up and mushrooms vegetables and discard pecans to coat . whisk 13x9x2 - 1 / 2 cup\n",
            "\n",
            "629/629 [==============================] - 70s 111ms/step - loss: 0.0091\n",
            "Epoch 14/25\n",
            "628/629 [============================>.] - ETA: 0s - loss: 0.0075\n",
            "generated text:\n",
            "recipe for spice dish cookies to cool 10 minutes , or or 1 hour uncovered , occasionally transfer to crust . cool cookies at prepared parchment paper towels . let cool generously , bread directly on top rack and chilled in arrange rack , where it side , allowing each , flatten up pot and right side . ( can be served restaurants still spreadable golden up the shrimp , , do to freeze juices from pork , , 5 minutes fresh more sauce , or or egg cookies instructions [UNK] remaining butter in middle of oven . garnish in\n",
            "\n",
            "629/629 [==============================] - 77s 123ms/step - loss: 0.0075\n",
            "Epoch 15/25\n",
            "629/629 [==============================] - ETA: 0s - loss: 0.0063\n",
            "generated text:\n",
            "recipe for onion skin dried shrimp if sticky to burn , until fish but slightly , about 20 minutes . then transfer skillet heat and bake of garlic to both - size ; brush water . keep in top of dough , for right side at one day ahead ; keep , turning occasionally with some some supermarkets and salmon peaches into shrimp slices . 2 chutney . \n",
            "\n",
            "629/629 [==============================] - 67s 107ms/step - loss: 0.0063\n",
            "Epoch 16/25\n",
            "629/629 [==============================] - ETA: 0s - loss: 0.0054\n",
            "generated text:\n",
            "recipe for platter and onion drumsticks the cream the lemongrass cook the cooked cobs floating liquid in cream a 2 cast - lined - 2 2 pieces . pass bananas still . in 2 pot of water . add corn slightly and cook lamb , and cook remaining 1 tablespoon oil until kernels liquid off tablespoonfuls enough soft betty liquid remains , until just very tender , about 3 minutes . cool dry inside onto each off side . turn duck liquid into pan juices into each serving . for 2 . chill . \n",
            "\n",
            "629/629 [==============================] - 72s 115ms/step - loss: 0.0054\n",
            "Epoch 17/25\n",
            "628/629 [============================>.] - ETA: 0s - loss: 0.0047\n",
            "generated text:\n",
            "recipe for cheeseburgers ( t the boil , stirring but yolks is thickened , stirring constantly , and 3 minutes . stir carefully any cobs . cook bottom in small saucepan . add the chard mixture in middle of oven with 1 / 3 won apart , and 3 hours to cool . meanwhile , to combine lemon juice , parmesan , parmesan , parmesan , parmesan sauce . serve \n",
            "\n",
            "629/629 [==============================] - 70s 111ms/step - loss: 0.0047\n",
            "Epoch 18/25\n",
            "629/629 [==============================] - ETA: 0s - loss: 0.0041\n",
            "generated text:\n",
            "recipe for 2 cups vichyssoise canapes to abut 2 with 2 filled to 6 cups paper as sticky ) about 2 minutes . return salad to cool consistency and saffron syrup , stirring occasionally mashing sear until beef over about coarse coarse tablespoonfuls more if needed . serve chicken , then a 1 baking pan and repeat with other side . slice off rings . top with vinaigrette and sprinkle with 1 teaspoon pepper . \n",
            "\n",
            "629/629 [==============================] - 76s 120ms/step - loss: 0.0041\n",
            "Epoch 19/25\n",
            "629/629 [==============================] - ETA: 0s - loss: 0.0036\n",
            "generated text:\n",
            "recipe for large shallow metal baking pan in pan flour and cook , until the liquid is slightly is dissolved , about 30 seconds , about 3 minutes , until fragrant , about 3 to 8 minutes . drain the soft moist minutes . using the beaters water . remove from heat , until a heat , until just for hot , about 25 to 2 hours . remove matzo or glossy . reduce the saucepan to moderately low . reduce heat to boil ; pat well in a saucepan and allow at a boil . add the hot profiteroles\n",
            "\n",
            "629/629 [==============================] - 75s 119ms/step - loss: 0.0036\n",
            "Epoch 20/25\n",
            "629/629 [==============================] - ETA: 0s - loss: 0.0031\n",
            "generated text:\n",
            "recipe for frijoles to medium - 2 cup let stand to cover ; cut cookies plastic wrap , or adding each rack . arrange mosaic prepared dish ; slice tuna . ) mix in onions to foil ; cook , until vegetables are about 25 minutes . toss batter into prepared pan ; bake until top is softened , about 1 hour - about 1 hour are done just longer . cool in each 6 plates , reserving shrimp . remove lid . drain in a small saucepan , a pot of boiling water , add carrot vinegar , and\n",
            "\n",
            "629/629 [==============================] - 72s 114ms/step - loss: 0.0031\n",
            "Epoch 21/25\n",
            "629/629 [==============================] - ETA: 0s - loss: 0.0027\n",
            "generated text:\n",
            "recipe for chicken . \n",
            "\n",
            "629/629 [==============================] - 66s 105ms/step - loss: 0.0027\n",
            "Epoch 22/25\n",
            "628/629 [============================>.] - ETA: 0s - loss: 0.0023\n",
            "generated text:\n",
            "recipe for 2 teaspoon aïoli lime cream the and in the half , stirring until scotch yolks but cooking just until cooked through and set aside . combine carefully any mosaic parsley and any it slide your addition be spatter . chill hens as many . strain the cooker . add cooked cobs are cooking liquid , smash white pepper , and cook until it moist incorporated , until it just combined remain browning given lumps remain . form depth pot . remove off that from carrot a deep - fry onions are translucent . the candied salt and pepper\n",
            "\n",
            "629/629 [==============================] - 76s 121ms/step - loss: 0.0023\n",
            "Epoch 23/25\n",
            "628/629 [============================>.] - ETA: 0s - loss: 0.0019\n",
            "generated text:\n",
            "recipe for 1 / 2 cup cream until slivered juice , dried cranberries juice , 2 tablespoons cream - 6 2 tablespoons spice bombes roll as cooked , cashews . bake , uncovered vegetables until parsley , , cheese mixture , and 1 cup stick on a small saucepan . finely cut quarter even layer , about 30 minutes , or 1 / 3 / 2 hours . ( can be made 6 days ahead ; repeat with its it . ( can be made 6 hours ahead . wrap bread and watch keep with generous 1 hours ahead .\n",
            "\n",
            "629/629 [==============================] - 75s 120ms/step - loss: 0.0019\n",
            "Epoch 24/25\n",
            "628/629 [============================>.] - ETA: 0s - loss: 0.0016\n",
            "generated text:\n",
            "recipe for 2 noodles . mix in a large skillet over medium - high and 5 minutes . ( spread open six from . using fingers ) . bake pastry squares in a large baking dish ; wrap . bake crust until slightly and just 5 minutes . add 1 1 / 2 inches butter is almost smooth and stiff but still produces just tender but still moves slightly , about 1 1 / 2 hours per side . remove from heat and let chicken on grill fish . reduce temperature from heat and let chicken to cover . (\n",
            "\n",
            "629/629 [==============================] - 76s 121ms/step - loss: 0.0016\n",
            "Epoch 25/25\n",
            "629/629 [==============================] - ETA: 0s - loss: 0.0014\n",
            "generated text:\n",
            "recipe for 2 - fry olive oil until cooked through , 20 minutes , fresh salt and pepper , drizzle bread and peel off pan . transfer cheesecake . rinse dough to a paring knife around crimp be shucked sheet , up to a large bowl . using electric baking sheet and pick . sprinkle steaks among prepared baking pan ; broil pan is just cooked through , about 30 to total . add brisket [UNK] the orange butter as pan , about 30 to 35 seconds . serve warm warm with chips and serve . ( can be made\n",
            "\n",
            "629/629 [==============================] - 73s 116ms/step - loss: 0.0014\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bb9afdcf2e0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the final model\n",
        "lstm.save(\"drive/MyDrive/models/lstm\")"
      ],
      "metadata": {
        "id": "172hTivtcduU"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generating Text using the LSTM Model"
      ],
      "metadata": {
        "id": "ZvJ-YlySRwhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lstm = models.load_model(\"drive/MyDrive/models/lstm\", compile=False)"
      ],
      "metadata": {
        "id": "QxsEQBWpR-Lu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PixelCNN\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "mgpuCf3uTn8E"
      }
    }
  ]
}