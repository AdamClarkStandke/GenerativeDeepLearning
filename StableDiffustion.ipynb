{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPs9ahDYWc89BloIkTeLf/k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AdamClarkStandke/GenerativeDeepLearning/blob/main/StableDiffustion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade keras-cv-nightly tf-nightly\n",
        "!pip install --upgrade keras-cv tensorflow\n",
        "!pip install --upgrade keras"
      ],
      "metadata": {
        "id": "Yv2IVHwLy6rE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "import keras_cv\n",
        "import keras"
      ],
      "metadata": {
        "id": "fEP56RaM09DI"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_cv.src import ops"
      ],
      "metadata": {
        "id": "IsI3wj_726dh"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CLIP"
      ],
      "metadata": {
        "id": "gjI1f1LVqd-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CLIPEmbedding(keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self, input_dim=49408, output_dim=768, max_length=77, **kwargs\n",
        "    ):\n",
        "        super().__init__(**kwargs)\n",
        "        self.token_embedding = keras.layers.Embedding(input_dim, output_dim)\n",
        "        self.position_embedding = keras.layers.Embedding(max_length, output_dim)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        tokens, positions = inputs\n",
        "        tokens = self.token_embedding(tokens)\n",
        "        positions = self.position_embedding(positions)\n",
        "        return tokens + positions\n",
        "\n",
        "\n",
        "class CLIPEncoderLayer(keras.layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, activation=None, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.layer_norm1 = keras.layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.clip_attn = CLIPAttention(embed_dim, num_heads, causal=True)\n",
        "        self.layer_norm2 = keras.layers.LayerNormalization(epsilon=1e-5)\n",
        "        self.fc1 = keras.layers.Dense(embed_dim * 4)\n",
        "        self.fc2 = keras.layers.Dense(embed_dim)\n",
        "        self.activation = activation\n",
        "\n",
        "    def call(self, inputs):\n",
        "        residual = inputs\n",
        "        x = self.layer_norm1(inputs)\n",
        "        x = self.clip_attn(x)\n",
        "        x = residual + x\n",
        "        residual = x\n",
        "        x = self.layer_norm2(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.fc2(x)\n",
        "        return x + residual\n",
        "\n",
        "class CLIPAttention(keras.layers.Layer):\n",
        "    def __init__(self, embed_dim=768, num_heads=12, causal=True, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.causal = causal\n",
        "        self.head_dim = self.embed_dim // self.num_heads\n",
        "        self.scale = self.head_dim**-0.5\n",
        "        self.q_proj = keras.layers.Dense(self.embed_dim)\n",
        "        self.k_proj = keras.layers.Dense(self.embed_dim)\n",
        "        self.v_proj = keras.layers.Dense(self.embed_dim)\n",
        "        self.out_proj = keras.layers.Dense(self.embed_dim)\n",
        "\n",
        "    def reshape_states(self, x, sequence_length, batch_size):\n",
        "        x = ops.reshape(\n",
        "            x, (batch_size, sequence_length, self.num_heads, self.head_dim)\n",
        "        )\n",
        "        return ops.transpose(\n",
        "            x, (0, 2, 1, 3)\n",
        "        )  # bs, heads, sequence_length, head_dim\n",
        "\n",
        "    def call(self, inputs, attention_mask=None):\n",
        "        if attention_mask is None and self.causal:\n",
        "            length = ops.shape(inputs)[1]\n",
        "            attention_mask = ops.triu(\n",
        "                ops.ones((1, 1, length, length), dtype=self.compute_dtype)\n",
        "                * -float(\"inf\"),\n",
        "                k=1,\n",
        "            )\n",
        "\n",
        "        _, tgt_len, embed_dim = inputs.shape\n",
        "        query_states = self.q_proj(inputs) * self.scale\n",
        "        key_states = self.reshape_states(self.k_proj(inputs), tgt_len, -1)\n",
        "        value_states = self.reshape_states(self.v_proj(inputs), tgt_len, -1)\n",
        "\n",
        "        proj_shape = (-1, tgt_len, self.head_dim)\n",
        "        query_states = self.reshape_states(query_states, tgt_len, -1)\n",
        "        query_states = ops.reshape(query_states, proj_shape)\n",
        "        key_states = ops.reshape(key_states, proj_shape)\n",
        "\n",
        "        src_len = tgt_len\n",
        "        value_states = ops.reshape(value_states, proj_shape)\n",
        "        attn_weights = query_states @ ops.transpose(key_states, (0, 2, 1))\n",
        "\n",
        "        attn_weights = ops.reshape(\n",
        "            attn_weights, (-1, self.num_heads, tgt_len, src_len)\n",
        "        )\n",
        "        attn_weights = attn_weights + attention_mask\n",
        "        attn_weights = ops.reshape(attn_weights, (-1, tgt_len, src_len))\n",
        "\n",
        "        attn_weights = ops.softmax(attn_weights, axis=-1)\n",
        "        attn_output = attn_weights @ value_states\n",
        "\n",
        "        attn_output = ops.reshape(\n",
        "            attn_output, (-1, self.num_heads, tgt_len, self.head_dim)\n",
        "        )\n",
        "        attn_output = ops.transpose(attn_output, (0, 2, 1, 3))\n",
        "        attn_output = ops.reshape(attn_output, (-1, tgt_len, embed_dim))\n",
        "        return self.out_proj(attn_output)"
      ],
      "metadata": {
        "id": "cfuDRaASqdFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Encoder"
      ],
      "metadata": {
        "id": "lWtzgKMLqBaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TextEncoder(keras.Model):\n",
        "    def __init__(\n",
        "        self, max_length, vocab_size=49408, name=None, download_weights=True\n",
        "    ):\n",
        "        tokens = keras.layers.Input(\n",
        "            shape=(max_length,), dtype=\"int32\", name=\"tokens\"\n",
        "        )\n",
        "        positions = keras.layers.Input(\n",
        "            shape=(max_length,), dtype=\"int32\", name=\"positions\"\n",
        "        )\n",
        "        x = CLIPEmbedding(vocab_size, 768, max_length)([tokens, positions])\n",
        "        for _ in range(12):\n",
        "            x = CLIPEncoderLayer(768, 12, activation=ops.)(x)\n",
        "        embedded = keras.layers.LayerNormalization(epsilon=1e-5)(x)\n",
        "        super().__init__([tokens, positions], embedded, name=name)\n",
        "\n",
        "        if download_weights:\n",
        "            text_encoder_weights_fpath = keras.utils.get_file(\n",
        "                origin=\"https://huggingface.co/fchollet/stable-diffusion/resolve/main/kcv_encoder.h5\",  # noqa: E501\n",
        "                file_hash=\"4789e63e07c0e54d6a34a29b45ce81ece27060c499a709d556c7755b42bb0dc4\",  # noqa: E501\n",
        "            )\n",
        "            self.load_weights(text_encoder_weights_fpath)"
      ],
      "metadata": {
        "id": "sfMQDgRmqATZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "FSprwHOmraEj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dFxont0GrZaf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}